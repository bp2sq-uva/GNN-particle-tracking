{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nDdVxA49UfYU",
    "outputId": "68cc8cfa-b376-4ff8-a166-549c7396cb9f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting dgl\n",
      "  Downloading dgl-1.1.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.0/6.0 MB\u001B[0m \u001B[31m23.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.3)\n",
      "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.7.22)\n",
      "Installing collected packages: dgl\n",
      "Successfully installed dgl-1.1.2\n",
      "Collecting torch_geometric\n",
      "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.0/1.0 MB\u001B[0m \u001B[31m11.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.7.22)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
      "Installing collected packages: torch_geometric\n",
      "Successfully installed torch_geometric-2.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install dgl\n",
    "!pip install torch_geometric\n",
    "#!pip install pandas google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.animation as animation\n",
    "import plotly.graph_objects as go"
   ],
   "metadata": {
    "id": "FVPmOKXlWBhH"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_10 = pd.read_csv(\"hit_data_seg_10.txt\", sep=\" \", header=None)\n",
    "df_11 = pd.read_csv(\"hit_data_seg_11.txt\", sep=\" \", header=None)\n",
    "df_12 = pd.read_csv(\"hit_data_seg_12.txt\", sep=\" \", header=None)\n",
    "df_13 = pd.read_csv(\"hit_data_seg_13.txt\", sep=\" \", header=None)\n",
    "df_14 = pd.read_csv(\"hit_data_seg_14.txt\", sep=\" \", header=None)\n",
    "df_15 = pd.read_csv(\"hit_data_seg_15.txt\", sep=\" \", header=None)"
   ],
   "metadata": {
    "id": "0ueDm4TGWKVa"
   },
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "column_names=[\"nevent\",\"Number of Tracks Found\",\"Number of good hits on all tracks\",\"Hits on track 1\",\"Hits on track 2\",\"Hits on track 3\",\"Track index\",\"GEM Layer\",\"Global X\",\"Global Y\",\n",
    "              \"Global X_Layer0\",\"Global Y_Layer0\",\"Layer0_On Track?\",\n",
    "              \"Global X_Layer1\",\"Global Y_Layer1\",\"Layer1_On Track?\",\n",
    "              \"Global X_Layer2\",\"Global Y_Layer2\",\"Layer2_On Track?\",\n",
    "              \"Global X_Layer3\",\"Global Y_Layer3\",\"Layer3_On Track?\",\n",
    "              \"Global X_Layer4-1\",\"Global Y_Layer4-1\",\"Layer4-1_On Track?\",\"Global X_Layer4-2\",\"Global Y_Layer4-2\",\"Layer4-2_On Track?\",\"Global X_Layer4-3\",\"Global Y_Layer4-3\",\"Layer4-3_On Track?\",\"Global X_Layer4-4\",\"Global Y_Layer4-4\",\"Layer4-4_On Track?\"]\n",
    "\n",
    "df_10.columns = column_names\n",
    "df_11.columns = column_names\n",
    "df_12.columns = column_names\n",
    "df_13.columns = column_names\n",
    "df_14.columns = column_names\n",
    "df_15.columns = column_names"
   ],
   "metadata": {
    "id": "_3Fbjx7YWfhi"
   },
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataframes = [df_10,df_11,df_12,df_13,df_14,df_15]\n",
    "\n",
    "adjustment = 0\n",
    "result_dfs = []\n",
    "\n",
    "for df_temp in dataframes:\n",
    "    df_copy = df_temp.copy()\n",
    "    df_copy['nevent'] += adjustment\n",
    "    result_dfs.append(df_copy)\n",
    "\n",
    "    adjustment = df_copy['nevent'].iloc[-1] + 1\n",
    "\n",
    "df = pd.concat(result_dfs, axis=0, ignore_index=True)"
   ],
   "metadata": {
    "id": "lvM9oJyIWq3K"
   },
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "filtered_df = df"
   ],
   "metadata": {
    "id": "DTR3-dR7LYzK"
   },
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "filtered_df = filtered_df.groupby('nevent').filter(lambda x: not ((x['Global X_Layer4-1'] != 0) & (x['Global X_Layer4-2'] != 0)).any())\n",
    "filtered_df = filtered_df.groupby('nevent').filter(lambda x: not ((x['Global X_Layer4-1'] != 0) & (x['Global X_Layer4-3'] != 0)).any())\n",
    "filtered_df = filtered_df.groupby('nevent').filter(lambda x: not ((x['Global X_Layer4-1'] != 0) & (x['Global X_Layer4-4'] != 0)).any())\n",
    "filtered_df = filtered_df.groupby('nevent').filter(lambda x: not ((x['Global X_Layer4-2'] != 0) & (x['Global X_Layer4-3'] != 0)).any())\n",
    "filtered_df = filtered_df.groupby('nevent').filter(lambda x: not ((x['Global X_Layer4-2'] != 0) & (x['Global X_Layer4-4'] != 0)).any())\n",
    "filtered_df = filtered_df.groupby('nevent').filter(lambda x: not ((x['Global X_Layer4-3'] != 0) & (x['Global X_Layer4-4'] != 0)).any())"
   ],
   "metadata": {
    "id": "hPahGh5LLbwt"
   },
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "filtered_df = filtered_df.groupby('nevent').filter(lambda x: not ((x['Global X_Layer4-1'] != 0) & (x['Global X_Layer4-2'] != 0)).any())\n",
    "filtered_df = filtered_df.groupby('nevent').filter(lambda x: not ((x['Global X_Layer4-1'] != 0) & (x['Global X_Layer4-3'] != 0)).any())\n",
    "filtered_df = filtered_df.groupby('nevent').filter(lambda x: not ((x['Global X_Layer4-1'] != 0) & (x['Global X_Layer4-4'] != 0)).any())\n",
    "filtered_df = filtered_df.groupby('nevent').filter(lambda x: not ((x['Global X_Layer4-2'] != 0) & (x['Global X_Layer4-3'] != 0)).any())\n",
    "filtered_df = filtered_df.groupby('nevent').filter(lambda x: not ((x['Global X_Layer4-2'] != 0) & (x['Global X_Layer4-4'] != 0)).any())\n",
    "filtered_df = filtered_df.groupby('nevent').filter(lambda x: not ((x['Global X_Layer4-3'] != 0) & (x['Global X_Layer4-4'] != 0)).any())"
   ],
   "metadata": {
    "id": "3Pkf_N4ELiim"
   },
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df.loc[df['Global X_Layer4-1'] == 0, 'Global X_Layer4-1'] = df.loc[df['Global X_Layer4-1'] == 0, 'Global X_Layer4-2']\n",
    "df.loc[df['Global Y_Layer4-1'] == 0, 'Global Y_Layer4-1'] = df.loc[df['Global Y_Layer4-1'] == 0, 'Global Y_Layer4-2']\n",
    "df.loc[df['Layer4-1_On Track?'] == 0, 'Layer4-1_On Track?'] = df.loc[df['Layer4-1_On Track?'] == 0, 'Layer4-2_On Track?']\n",
    "\n",
    "df.loc[df['Global X_Layer4-1'] == 0, 'Global X_Layer4-1'] = df.loc[df['Global X_Layer4-1'] == 0, 'Global X_Layer4-3']\n",
    "df.loc[df['Global Y_Layer4-1'] == 0, 'Global Y_Layer4-1'] = df.loc[df['Global Y_Layer4-1'] == 0, 'Global Y_Layer4-3']\n",
    "df.loc[df['Layer4-1_On Track?'] == 0, 'Layer4-1_On Track?'] = df.loc[df['Layer4-1_On Track?'] == 0, 'Layer4-3_On Track?']\n",
    "\n",
    "df.loc[df['Global X_Layer4-1'] == 0, 'Global X_Layer4-1'] = df.loc[df['Global X_Layer4-1'] == 0, 'Global X_Layer4-4']\n",
    "df.loc[df['Global Y_Layer4-1'] == 0, 'Global Y_Layer4-1'] = df.loc[df['Global Y_Layer4-1'] == 0, 'Global Y_Layer4-4']\n",
    "df.loc[df['Layer4-1_On Track?'] == 0, 'Layer4-1_On Track?'] = df.loc[df['Layer4-1_On Track?'] == 0, 'Layer4-4_On Track?']"
   ],
   "metadata": {
    "id": "TYeHjBGuLlBD"
   },
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df.rename(columns={'Global X_Layer4-1': 'Global X_Layer4'}, inplace=True)\n",
    "df.rename(columns={'Global Y_Layer4-1': 'Global Y_Layer4'}, inplace=True)\n",
    "df.rename(columns={'Layer4-1_On Track?': 'Layer4_On Track?'}, inplace=True)"
   ],
   "metadata": {
    "id": "frh9WlKuLnd6"
   },
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df.drop(columns=['Global X_Layer4-2', 'Global X_Layer4-3', 'Global X_Layer4-4'], inplace=True)\n",
    "df.drop(columns=['Global Y_Layer4-2', 'Global Y_Layer4-3', 'Global Y_Layer4-4'], inplace=True)\n",
    "df.drop(columns=['Layer4-2_On Track?', 'Layer4-3_On Track?', 'Layer4-4_On Track?'], inplace=True)"
   ],
   "metadata": {
    "id": "h-SUTJZaLuXy"
   },
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_filtered = df[(df['Global X_Layer0'] != 0) | (df['Global X_Layer1'] != 0) | (df['Global X_Layer2'] != 0) | (df['Global X_Layer3'] != 0) | (df['Global X_Layer4'] != 0)]\n",
    "df_filtered = df_filtered[(df_filtered['Number of Tracks Found'] ==1)]\n",
    "\n",
    "#df_filtered = df_filtered_2.copy()\n",
    "df_filtered.reset_index(drop=True, inplace=True)"
   ],
   "metadata": {
    "id": "_HPC9HXPLw5O"
   },
   "execution_count": 47,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "parsed_GEn_dataset = df_filtered\n",
    "\n",
    "df.to_csv('parsed_GEn_dataset.txt', sep=' ', index=False, header=False)"
   ],
   "metadata": {
    "id": "QqWcmRiaQsMC"
   },
   "execution_count": 53,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "data_list = []\n",
    "\n",
    "nevent = []\n",
    "dataset = []\n",
    "y = []\n",
    "edges = []\n",
    "dataset_2D = []\n",
    "hit_layer = []\n",
    "dist_test = []\n",
    "\n",
    "for event in range(df_filtered['nevent'].nunique()):\n",
    "    if (df_filtered['nevent'].isin([event]).any()):\n",
    "        df_portion = df_filtered[df_filtered['nevent']==event]\n",
    "\n",
    "        layer = []\n",
    "        layer_X = []\n",
    "        layer_Y = []\n",
    "        layer_Z = []\n",
    "        target = []\n",
    "        coordinates = [[], [], []]\n",
    "        edge_index = []\n",
    "        coordinates_2D = [[], []]\n",
    "\n",
    "        #if 0 in df_portion['GEM Layer'].values:\n",
    "        nevent += [event] * ((df_portion['Global X_Layer0'] != 0).sum())\n",
    "        layer_X.extend(df_portion.iloc[0:(df_portion['Global X_Layer0'] != 0).sum()]['Global X_Layer0'].values.tolist())\n",
    "        layer_Y.extend(df_portion.iloc[0:(df_portion['Global X_Layer0'] != 0).sum()]['Global Y_Layer0'].values.tolist())\n",
    "        layer_Z += [1] * ((df_portion['Global X_Layer0'] != 0).sum())\n",
    "        layer += [0] * ((df_portion['Global X_Layer0'] != 0).sum())\n",
    "        target.extend(df_portion.iloc[0:(df_portion['Global X_Layer0'] != 0).sum()][\"Layer0_On Track?\"].values.tolist())\n",
    "\n",
    "#if 1 in df_portion['GEM Layer'].values:\n",
    "        nevent += [event] * ((df_portion['Global X_Layer1'] != 0).sum())\n",
    "        layer_X.extend(df_portion.iloc[0:(df_portion['Global X_Layer1'] != 0).sum()]['Global X_Layer1'].values.tolist())\n",
    "        layer_Y.extend(df_portion.iloc[0:(df_portion['Global X_Layer1'] != 0).sum()]['Global Y_Layer1'].values.tolist())\n",
    "        layer_Z += [2] * ((df_portion['Global X_Layer1'] != 0).sum())\n",
    "        layer += [1] * ((df_portion['Global X_Layer1'] != 0).sum())\n",
    "        target.extend(df_portion.iloc[0:(df_portion['Global X_Layer1'] != 0).sum()][\"Layer1_On Track?\"].values.tolist())\n",
    "\n",
    "\n",
    "#if 2 in df_portion['GEM Layer'].values:\n",
    "        nevent += [event] * ((df_portion['Global X_Layer2'] != 0).sum())\n",
    "        layer_X.extend(df_portion.iloc[0:(df_portion['Global X_Layer2'] != 0).sum()]['Global X_Layer2'].values.tolist())\n",
    "        layer_Y.extend(df_portion.iloc[0:(df_portion['Global X_Layer2'] != 0).sum()]['Global Y_Layer2'].values.tolist())\n",
    "        layer_Z += [3] * ((df_portion['Global X_Layer2'] != 0).sum())\n",
    "        layer += [2] * ((df_portion['Global X_Layer2'] != 0).sum())\n",
    "        target.extend(df_portion.iloc[0:(df_portion['Global X_Layer2'] != 0).sum()][\"Layer2_On Track?\"].values.tolist())\n",
    "\n",
    "\n",
    "#if 3 in df_portion['GEM Layer'].values:\n",
    "        nevent += [event] * ((df_portion['Global X_Layer3'] != 0).sum())\n",
    "        layer_X.extend(df_portion.iloc[0:(df_portion['Global X_Layer3'] != 0).sum()]['Global X_Layer3'].values.tolist())\n",
    "        layer_Y.extend(df_portion.iloc[0:(df_portion['Global X_Layer3'] != 0).sum()]['Global Y_Layer3'].values.tolist())\n",
    "        layer_Z += [4] * ((df_portion['Global X_Layer3'] != 0).sum())\n",
    "        layer += [3] * ((df_portion['Global X_Layer3'] != 0).sum())\n",
    "        target.extend(df_portion.iloc[0:(df_portion['Global X_Layer3'] != 0).sum()][\"Layer3_On Track?\"].values.tolist())\n",
    "\n",
    "\n",
    "#if 4 in df_portion['GEM Layer'].values:\n",
    "        nevent += [event] * ((df_portion['Global X_Layer4'] != 0).sum())\n",
    "        layer_X.extend(df_portion.iloc[0:(df_portion['Global X_Layer4'] != 0).sum()]['Global X_Layer4'].values.tolist())\n",
    "        layer_Y.extend(df_portion.iloc[0:(df_portion['Global X_Layer4'] != 0).sum()]['Global Y_Layer4'].values.tolist())\n",
    "        layer_Z += [5] * ((df_portion['Global X_Layer4'] != 0).sum())\n",
    "        layer += [4] * ((df_portion['Global X_Layer4'] != 0).sum())\n",
    "        target.extend(df_portion.iloc[0:(df_portion['Global X_Layer4'] != 0).sum()][\"Layer4_On Track?\"].values.tolist())\n",
    "\n",
    "        coordinates[0].append(layer_X)\n",
    "        coordinates[1].append(layer_Y)\n",
    "        coordinates[2].append(layer_Z)\n",
    "\n",
    "        column1 = np.array(coordinates)[0, 0]\n",
    "        column2 = np.array(coordinates)[1, 0]\n",
    "        column3 = np.array(coordinates)[2, 0]\n",
    "        coordinates_array = np.column_stack((column1, column2, column3))\n",
    "        coordinates_2D = np.array(np.column_stack((column1, column2)), dtype=np.float32)\n",
    "\n",
    "        z_coordinates = coordinates_array[:, 2]\n",
    "\n",
    "        #distances = 1 / (cdist(z_coordinates.reshape(-1, 1), z_coordinates.reshape(-1, 1)) + 0.1)\n",
    "        distances_z = (cdist(z_coordinates.reshape(-1, 1), z_coordinates.reshape(-1, 1)) + 0.1)\n",
    "        distances_2D = (cdist(coordinates_2D, coordinates_2D))\n",
    "\n",
    "\n",
    "        dist_test.append(distances_2D)\n",
    "\n",
    "        distance_threshold_z = 1.2\n",
    "        distance_threshold_2D = 0.15\n",
    "\n",
    "        edge_index = []\n",
    "        for i in range(len(coordinates_array)):\n",
    "            for j in range(i + 1, len(coordinates_array)):\n",
    "                if distances_z[i, j] < distance_threshold_z:\n",
    "                  if distances_2D[i, j] < distance_threshold_2D:\n",
    "                    edge_index.append([i, j])\n",
    "                    edge_index.append([j, i])\n",
    "        edge_index = np.array(edge_index).T\n",
    "\n",
    "\n",
    "#### ########### ########### ########### ########### ########### ########### ########### ###########\n",
    "#### FILTER FOR REACH OF THE LINKS(Set to consider events that has hits on layers - 0,1,2,3,4) ######\n",
    "#### ########### ########### ########### ########### ########### ########### ########### ###########\n",
    "        indices = [i for i, value in enumerate(target) if value == 1]\n",
    "\n",
    "        # Get the corresponding values in the 'layer' array\n",
    "        corresponding_layer_values = [layer[i] for i in indices]\n",
    "\n",
    "        event_data = {\n",
    "            #'coordinates': coordinates,\n",
    "            'coordinates_2D': coordinates_2D,\n",
    "            'target': target,\n",
    "            'edge_index': edge_index,\n",
    "            'layer': layer\n",
    "        }\n",
    "\n",
    "        if (corresponding_layer_values == [0, 1, 2, 3, 4]):\n",
    "          data_list.append(event_data)"
   ],
   "metadata": {
    "id": "SlSL-FnJL0WW"
   },
   "execution_count": 48,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "JTxNXa-qMGM4"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
